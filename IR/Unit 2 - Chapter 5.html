<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Unit 2 - Chapter 5</title><style type="text/css"> * {margin:0; padding:0; text-indent:0; }
 .s1 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 44pt; }
 .s2 { color: black; font-family:"Times New Roman", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 28pt; }
 .s3 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 28pt; }
 .p, p { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; margin:0pt; }
 .s4 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 20pt; }
 .s5 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 36pt; }
 .s7 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 32pt; }
 .s8 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 19pt; vertical-align: -8pt; }
 .s9 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; vertical-align: 9pt; }
 .s10 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 19pt; vertical-align: -8pt; }
 .h2, h2 { color: #33C; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 24pt; }
 .s11 { color: #33C; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; }
 .s12 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 21pt; vertical-align: -9pt; }
 .s13 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 21pt; vertical-align: -9pt; }
 .s14 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 16pt; vertical-align: -6pt; }
 .s15 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 16pt; vertical-align: -6pt; }
 .s16 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .h1, h1 { color: #33C; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 28pt; }
 .s17 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 40pt; }
 .s18 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; vertical-align: 2pt; }
 .s19 { color: #C30; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 24pt; }
 .s20 { color: black; font-family:"Arial Unicode MS", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 28pt; }
 .s21 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 28pt; }
 .s22 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 13pt; vertical-align: -5pt; }
 .s23 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 13pt; vertical-align: -5pt; }
 .s24 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 19pt; }
 .s25 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; vertical-align: -22pt; }
 .s26 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; vertical-align: -14pt; }
 .s27 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; vertical-align: -4pt; }
 .s28 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; vertical-align: -5pt; }
 .s29 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; vertical-align: 7pt; }
 .s30 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; vertical-align: 18pt; }
 .s31 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 32pt; vertical-align: 8pt; }
 .s32 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; vertical-align: 2pt; }
 .s34 { color: #33C; font-family:TimesNewRomanPS-BoldItalicMT, serif; font-style: italic; font-weight: bold; text-decoration: none; font-size: 24pt; }
 .s35 { color: black; font-family:"Arial Unicode MS", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; }
 .s36 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; vertical-align: -3pt; }
 .s37 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; vertical-align: -9pt; }
 li {display: block; }
 #l1 {padding-left: 0pt; }
 #l1> li>*:first-child:before {content: "• "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l2 {padding-left: 0pt; }
 #l2> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l3 {padding-left: 0pt; }
 #l3> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l4 {padding-left: 0pt; }
 #l4> li>*:first-child:before {content: "• "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 20pt; }
 #l5 {padding-left: 0pt; }
 #l5> li>*:first-child:before {content: "• "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 20pt; }
 #l6 {padding-left: 0pt; }
 #l6> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l7 {padding-left: 0pt; }
 #l7> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l8 {padding-left: 0pt; }
 #l8> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 li {display: block; }
 #l9 {padding-left: 0pt; }
 #l9> li>*:first-child:before {content: "• "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 28pt; }
 #l10 {padding-left: 0pt; }
 #l10> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; }
 li {display: block; }
 #l11 {padding-left: 0pt; }
 #l11> li>*:first-child:before {content: "• "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 28pt; }
 #l12 {padding-left: 0pt; }
 #l12> li>*:first-child:before {content: "• "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l13 {padding-left: 0pt; }
 #l13> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l14 {padding-left: 0pt; }
 #l14> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l15 {padding-left: 0pt; }
 #l15> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l16 {padding-left: 0pt; }
 #l16> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l17 {padding-left: 0pt; }
 #l17> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l18 {padding-left: 0pt; }
 #l18> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l19 {padding-left: 0pt; }
 #l19> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l20 {padding-left: 0pt; }
 #l20> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l21 {padding-left: 0pt; }
 #l21> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l22 {padding-left: 0pt; }
 #l22> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l23 {padding-left: 0pt; }
 #l23> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l24 {padding-left: 0pt; }
 #l24> li>*:first-child:before {content: "• "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 20pt; }
 #l25 {padding-left: 0pt; }
 #l25> li>*:first-child:before {content: "• "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 20pt; }
 #l26 {padding-left: 0pt; }
 #l26> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l27 {padding-left: 0pt; }
 #l27> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l28 {padding-left: 0pt; }
 #l28> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l29 {padding-left: 0pt; }
 #l29> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l30 {padding-left: 0pt; }
 #l30> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l31 {padding-left: 0pt; }
 #l31> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l32 {padding-left: 0pt; }
 #l32> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l33 {padding-left: 0pt; }
 #l33> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l34 {padding-left: 0pt; }
 #l34> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l35 {padding-left: 0pt; }
 #l35> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l36 {padding-left: 0pt; }
 #l36> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l37 {padding-left: 0pt; }
 #l37> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l38 {padding-left: 0pt; }
 #l38> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l39 {padding-left: 0pt; }
 #l39> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l40 {padding-left: 0pt; }
 #l40> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l41 {padding-left: 0pt; }
 #l41> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l42 {padding-left: 0pt; }
 #l42> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l43 {padding-left: 0pt; }
 #l43> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l44 {padding-left: 0pt; }
 #l44> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l45 {padding-left: 0pt; }
 #l45> li>*:first-child:before {content: "• "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 20pt; }
 #l46 {padding-left: 0pt; }
 #l46> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l47 {padding-left: 0pt; }
 #l47> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l48 {padding-left: 0pt; }
 #l48> li>*:first-child:before {content: "• "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 20pt; }
 #l49 {padding-left: 0pt; }
 #l49> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l50 {padding-left: 0pt; }
 #l50> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
 #l51 {padding-left: 0pt; }
 #l51> li>*:first-child:before {content: "– "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 24pt; }
 #l52 {padding-left: 0pt; }
 #l52> li>*:first-child:before {content: "• "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; }
</style></head><body><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-top: 3pt;padding-left: 202pt;text-indent: 70pt;text-align: left;">Chapter 5 Query Operations</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-top: 3pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">Paraphrase Problem in IR</p><ul id="l1"><li><p class="s2" style="padding-top: 42pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">Users often input queries containing terms that do not match the terms used to index the majority of the relevant documents.</p></li><li><p class="s3" style="padding-top: 6pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">relevance feedback and query modification</p><ul id="l2"><li><p style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">reweighting of the query terms based on the distribution of these terms in the relevant and nonrelevant documents retrieved in response to those queries</p></li><li><p style="padding-top: 5pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">changing the actual terms in the query</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;text-indent: 0pt;text-align: right;">2</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-top: 3pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">Query Reformulation</p></li></ul></li><li><p class="s3" style="padding-top: 42pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">basic steps</p><ul id="l3"><li><p style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">query expansion: expanding the original query with new terms</p><ul id="l4"><li><p class="s4" style="padding-top: 3pt;padding-left: 149pt;text-indent: -15pt;text-align: left;">feedback information from the user</p></li><li><p class="s4" style="padding-top: 6pt;padding-left: 149pt;text-indent: -15pt;text-align: left;">information derived from the set of documents initially retrieved (local set of documents)</p></li><li><p class="s4" style="padding-top: 3pt;padding-left: 149pt;text-indent: -15pt;text-align: left;">global information derived from document collection</p></li></ul></li><li><p style="padding-top: 4pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">term reweighting</p><ul id="l5"><li><p class="s4" style="padding-top: 5pt;padding-left: 149pt;text-indent: -15pt;text-align: left;">reweighting the terms in the expanded query</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;text-indent: 0pt;text-align: right;">3</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s5" style="padding-top: 9pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">User Relevance Feedback</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li></ul></li></ul></li><li><p class="s3" style="padding-left: 86pt;text-indent: -22pt;text-align: justify;">U: Query is submitted</p></li><li><p class="s3" style="padding-top: 3pt;padding-left: 86pt;text-indent: -22pt;text-align: justify;">S: A list of the retrieved documents is presented</p></li><li><p class="s3" style="padding-top: 5pt;padding-left: 86pt;text-indent: -22pt;line-height: 93%;text-align: justify;">U: The documents are examined and the relevant ones are marked</p></li><li><p class="s3" style="padding-top: 5pt;padding-left: 86pt;text-indent: -22pt;line-height: 93%;text-align: justify;">S: The important terms/expressions are selected from the documents that have been identified as relevant</p></li><li><p class="s3" style="padding-top: 6pt;padding-left: 86pt;text-indent: -22pt;line-height: 93%;text-align: justify;">The relevance feedback cycle is repeated several times</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;text-indent: 0pt;text-align: right;">4</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s4" style="padding-top: 9pt;padding-left: 82pt;text-indent: 0pt;text-align: center;"><span class="s5">User Relevance Feedback </span>(<i>Continued</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s7" style="padding-left: 86pt;text-indent: -22pt;text-align: left;">advantages</p><ul id="l6"><li><p class="s3" style="padding-top: 7pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Shield the details of the query reformulation</p></li><li><p class="s3" style="padding-top: 7pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Break down the whole searching task into a sequence of small steps</p></li><li><p class="s3" style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Provide a controlled process designed to emphasize some terms (relevant ones) and de-emphasize others (non-relevant ones)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 10pt;text-indent: 0pt;text-align: right;">5</p><p class="s5" style="padding-top: 2pt;padding-left: 206pt;text-indent: -143pt;text-align: left;">Query Expansion and Term Reweighting for the Vector Model</p></li></ul></li><li><p class="s7" style="padding-top: 25pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">basic idea</p><ul id="l7"><li><p class="s3" style="padding-top: 7pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Relevant documents resemble each other</p></li><li><p class="s3" style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Non-relevant documents have term-weight vectors which are dissimilar from the ones for the relevant documents</p></li><li><p class="s3" style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">The reformulated query is moved to closer to the term-weight vector space of relevant documents</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 10pt;text-indent: 0pt;text-align: right;">6</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 17pt;text-indent: 0pt;text-align: left;"><span><img width="896" height="428" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_001.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 12pt;text-indent: 0pt;text-align: right;">7</p><p class="s4" style="padding-top: 2pt;padding-left: 153pt;text-indent: -90pt;text-align: left;"><span class="s5">Query Expansion and Term Reweighting for the Vector Model </span>(<i>Continued</i>)</p><p style="text-indent: 0pt;text-align: left;"><span><img width="608" height="465" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_002.png"/></span></p><p class="s3" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 35pt;text-align: left;">D<span class="s8">r</span>: set of relevant documents, as identified by the user</p><p class="s3" style="padding-left: 328pt;text-indent: 0pt;line-height: 35pt;text-align: left;">D<span class="s8">n</span>: set of non-relevant documents</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s3" style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">the retrieved documents</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s3" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">collection</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s3" style="padding-top: 3pt;padding-left: 29pt;text-indent: 0pt;text-align: left;">C<span class="s8">r</span>: set of relevant documents</p><p class="s3" style="padding-top: 5pt;padding-left: 348pt;text-indent: 0pt;text-align: left;">set of non-relev<span class="s9">8</span>ant documents</p><p class="s4" style="padding-top: 2pt;padding-left: 153pt;text-indent: -90pt;text-align: left;"><span class="s5">Query Expansion and Term Reweighting for the Vector Model </span>(<i>Continued</i>)</p><p style="text-indent: 0pt;text-align: left;"><span><img width="634" height="162" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_003.png"/></span></p></li></ul></li><li><p class="s3" style="padding-top: 27pt;padding-left: 86pt;text-indent: -22pt;line-height: 88%;text-align: left;">when complete set C<span class="s8">r</span><span class="s10"> </span>of relevant documents is known</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s3" style="padding-top: 18pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">when the set C<span class="s8">r</span><span class="s10"> </span>are not known a priori</p><ul id="l8"><li><p style="padding-left: 118pt;text-indent: -22pt;text-align: left;">Formulate an initial query</p></li><li><p style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Incrementally change the initial query vector</p></li></ul></li></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 10pt;text-indent: 0pt;text-align: right;">9</p><ul id="l9"><li><p class="s3" style="padding-top: 3pt;padding-left: 92pt;text-indent: -22pt;text-align: left;">Calculate the modified query</p><p style="text-indent: 0pt;text-align: left;"><span><img width="570" height="117" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_004.png"/></span></p><h2 style="padding-left: 26pt;text-indent: 0pt;line-height: 25pt;text-align: left;">expansion</h2><p style="text-indent: 0pt;text-align: left;"/><ul id="l10"><li><p style="padding-top: 3pt;padding-left: 124pt;text-indent: -22pt;text-align: left;">Standard-Rochio</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="472" height="68" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_005.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="244" height="32" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_006.png"/></span></p><p class="s11" style="padding-left: 9pt;text-indent: 0pt;line-height: 27pt;text-align: left;">term reweighting</p><p style="text-indent: 0pt;text-align: left;"/></li><li><p style="padding-left: 124pt;text-indent: -22pt;text-align: left;">Ide-Regular</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 124pt;text-indent: -22pt;text-align: left;">Ide-Dec-Hi</p><h2 style="padding-top: 20pt;padding-left: 19pt;text-indent: 0pt;text-align: left;">query</h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="537" height="138" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_007.png"/></span></p></li><li><p style="padding-top: 9pt;padding-left: 124pt;text-indent: -22pt;text-align: left;">α, β, γ: tuning constants (usually, β&gt;γ)</p><p style="padding-left: 101pt;text-indent: 0pt;line-height: 26pt;text-align: left;">– α=1 (Rochio, 1971)</p><p style="padding-top: 5pt;padding-left: 101pt;text-indent: 0pt;text-align: left;">– α=β=γ=1 (Ide, 1971)</p></li><li><p style="padding-top: 3pt;padding-left: 124pt;text-indent: -22pt;text-align: left;">γ=0: positive feedback</p></li></ul></li></ul><p style="padding-left: 101pt;text-indent: 0pt;line-height: 27pt;text-align: left;">the highest ranked</p><p style="padding-top: 1pt;padding-left: 101pt;text-indent: 0pt;text-align: left;">non-relevant document</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 1pt;padding-left: 23pt;text-indent: 0pt;text-align: left;">Similar performance</p><p style="padding-left: 220pt;text-indent: 0pt;text-align: left;"/><p class="s3" style="padding-top: 2pt;padding-left: 35pt;text-indent: 0pt;text-align: left;">positive relevance-feedback α=β=1 and γ=0</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 17pt;text-indent: 0pt;text-align: left;"><span><img width="896" height="428" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_008.jpg"/></span></p><ul id="l11"><li><p class="s3" style="padding-top: 2pt;padding-left: 78pt;text-indent: -22pt;text-align: left;">“dec hi” method: use all relevant information, but subtract only the highest ranked nonrelevant document</p></li><li><p class="s3" style="padding-top: 4pt;padding-left: 78pt;text-indent: -22pt;text-align: left;">feedback with query splitting</p><p class="s11" style="padding-top: 3pt;padding-left: 78pt;text-indent: 0pt;text-align: left;">solve problems: (1) the relevant documents identified do not form a tight cluster; (2) nonrelevant documents are scattered among certain relevant ones</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="680" height="282" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_009.png"/></span></p><p class="s11" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">homogeneous relevant items</p><p class="s11" style="padding-top: 9pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">homogeneous relevant items</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-top: 3pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">Analysis</p><ul id="l12"><li><p class="s7" style="padding-top: 42pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">advantages</p><ul id="l13"><li><p class="s3" style="padding-top: 7pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">simplicity</p></li><li><p class="s3" style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">good results</p></li></ul></li><li><p class="s7" style="padding-top: 8pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">disadvantages</p><ul id="l14"><li><p class="s3" style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">No optimality criterion is adopted</p><p class="s1" style="padding-top: 1pt;padding-left: 184pt;text-indent: -35pt;text-align: left;">Term Weighting for the Probabilistic Model</p></li></ul></li><li><p class="s7" style="padding-top: 13pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">The similarity of a document d<span class="s12">j</span><span class="s13"> </span>to a query q</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 57pt;text-indent: 0pt;text-align: left;"><span><img width="825" height="87" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_010.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="113" height="40" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_011.png"/></span></p><p style="padding-top: 29pt;padding-left: 149pt;text-indent: -12pt;line-height: 91%;text-align: left;">: the probability of observing the term k<span class="s14">i</span><span class="s15"> </span>in the set R of relevant documents</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 623pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="32" height="1" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_012.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="113" height="43" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_013.png"/></span></p><p style="padding-left: 155pt;text-indent: -12pt;line-height: 91%;text-align: left;">: the probability of observing the term k<span class="s14">i</span><span class="s15"> </span>in the set R of non-relevant documents</p><p style="text-indent: 0pt;text-align: left;"><span><img width="202" height="44" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_014.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="184" height="80" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_015.png"/></span></p><p style="padding-top: 8pt;padding-left: 64pt;text-indent: 0pt;text-align: left;">Initial search:</p><p style="text-indent: 0pt;text-align: left;"><span><img width="202" height="44" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_016.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="168" height="73" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_017.png"/></span></p><h2 style="padding-top: 8pt;padding-left: 47pt;text-indent: 0pt;text-align: left;">Initial search<span class="p">:</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 47pt;text-indent: 0pt;text-align: left;"><span><img width="837" height="347" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_018.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-top: 3pt;padding-left: 59pt;text-indent: 0pt;text-align: left;">Feedback search:</h2><p class="s16" style="padding-left: 95pt;text-indent: 0pt;text-align: left;"><span><img width="278" height="86" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_019.png"/></span>	<span><img width="422" height="95" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_020.png"/></span></p><h2 style="padding-top: 2pt;padding-left: 59pt;text-indent: 0pt;text-align: left;">Feedback search:</h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 130pt;text-indent: 0pt;text-align: left;"><span><img width="223" height="88" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_021.png"/></span>	<span><img width="300" height="96" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_022.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 53pt;text-indent: 0pt;text-align: left;"><span><img width="840" height="386" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_023.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-top: 11pt;padding-left: 17pt;text-indent: 0pt;text-align: left;">No query expansion occurs</h2><p style="padding-left: 202pt;text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><span><img width="521" height="184" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_024.png"/></span></p><p style="padding-top: 2pt;padding-left: 64pt;text-indent: -6pt;line-height: 158%;text-align: left;">For small values of |D<span class="s14">r</span>| and |D<span class="s14">r,i</span>| (i.e., |D<span class="s14">r</span>|=1, |D<span class="s14">r,i</span>|=0) <span style=" color: #33C;">Alternative 1:</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="332" height="248" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_025.png"/></span></p><p class="s11" style="padding-left: 70pt;text-indent: 0pt;text-align: left;">Alternative 2:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-top: 3pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">Analysis</p></li><li><p class="s3" style="padding-top: 42pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">advantages</p><ul id="l15"><li><p style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Feedback process is directly related to the derivation of new weights for query terms</p></li><li><p style="padding-top: 3pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">The term reweighting is optimal</p></li></ul></li><li><p class="s3" style="padding-top: 7pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">disadvantages</p><ul id="l16"><li><p style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Document term weights are not considered</p></li><li><p style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Weights of terms in previous query formulations are disregarded</p></li><li><p style="padding-top: 5pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">No query expansion is used</p><p class="s1" style="padding-top: 1pt;padding-left: 76pt;text-indent: 171pt;text-align: left;">A Variant of Probabilistic Term Reweighting</p></li></ul></li><li><p class="s7" style="padding-top: 13pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">variant</p><ul id="l17"><li><p class="s3" style="padding-top: 7pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">distinct initial search method</p></li><li><p class="s3" style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">include within-document frequency weights</p></li></ul></li><li><p class="s7" style="padding-top: 8pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">initial search</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 11pt;text-indent: 0pt;line-height: 27pt;text-align: left;">Similar to</p><p style="padding-left: 11pt;text-indent: 0pt;text-align: left;">tf-idf scheme</p><p class="s16" style="padding-left: 173pt;text-indent: 0pt;text-align: left;"><span><img width="366" height="246" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_026.png"/></span>	</p><p style="padding-top: 2pt;padding-left: 71pt;text-indent: -48pt;text-align: left;">C=0 for automatically indexed collections or for feedback searching (allow IDF or the relevance weighting to be the dominant factor)</p><p style="padding-left: 23pt;text-indent: 0pt;line-height: 26pt;text-align: left;">C&gt;0 for manually indexed collections</p><p style="padding-top: 2pt;padding-left: 77pt;text-indent: -6pt;text-align: left;">(allow the mere existence of a term within a document to carry more weight)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 71pt;text-indent: -48pt;text-align: left;">K=0.3 for initial search of regular length documents (documents having many multiple occurrences of a term)</p><p style="padding-left: 23pt;text-indent: 0pt;text-align: left;">K=0.5 for feedback searches</p><p style="padding-left: 65pt;text-indent: -42pt;text-align: left;">K=1 for short documents: the within-document frequency is removed (the within-document frequency plays a minimum role)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h1 style="padding-bottom: 1pt;padding-left: 23pt;text-indent: 0pt;text-align: left;">Feedback search</h1><p style="padding-left: 101pt;text-indent: 0pt;text-align: left;"><span><img width="674" height="103" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_027.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-top: 3pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">Analysis</p></li><li><p class="s7" style="padding-top: 42pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">advantages</p><ul id="l18"><li><p class="s3" style="padding-top: 7pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">The within-document frequencies are considered</p></li><li><p class="s3" style="padding-top: 7pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">A normalized version of these frequencies is adopted</p></li><li><p class="s3" style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Constants C and K are introduced</p></li></ul></li><li><p class="s7" style="padding-top: 8pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">disadvantages</p><ul id="l19"><li><p class="s3" style="padding-top: 7pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">more complex formulation</p></li><li><p class="s3" style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">no query expansion</p><p class="s1" style="padding-top: 1pt;padding-left: 65pt;text-indent: 0pt;text-align: left;">Evaluation of relevance feedback</p></li></ul></li><li><p class="s3" style="padding-top: 29pt;padding-left: 86pt;text-indent: -22pt;line-height: 93%;text-align: left;">Standard evaluation (i.e., recall-precision) method is not suitable, because the relevant documents used to reweight the query terms moving to higher ranks.</p></li><li><p class="s3" style="padding-top: 4pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">The residual collection method</p><p style="text-indent: 0pt;text-align: left;"><span><img width="23" height="4" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_028.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="23" height="4" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_029.png"/></span></p><ul id="l20"><li><p style="padding-top: 4pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">the evaluation of the results compares only the residual collections, i.e., the initial run is remade minus the documents previously shown to the user and this is compared with the feedback run minus the same documents</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 12pt;text-indent: 0pt;line-height: 91%;text-align: left;">Note that q<span class="s14">m </span>tend to be lower than the figures for the original</p><p style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">query vector q in <span class="h2">residual collection</span></p><p style="padding-left: 238pt;text-indent: 0pt;text-align: left;"/><p class="s17" style="padding-top: 1pt;padding-left: 184pt;text-indent: -24pt;text-align: left;">Residual Collection with Partial Rank Freezing</p><p style="text-indent: 0pt;text-align: left;"><span><img width="740" height="384" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_030.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s11" style="padding-top: 15pt;padding-left: 222pt;text-indent: 0pt;text-align: left;">Assume 10 documents are relevant.</p><p style="text-indent: 0pt;text-align: left;"/></li></ul></li><li><p style="padding-top: 18pt;padding-left: 86pt;text-indent: -23pt;text-align: justify;">The previously retrieved items identified as relevant are kept “frozen”; and the previously retrieved nonrelevant items are simple removed from the collection.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 27pt;text-align: left;">Hsin-Hsi</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 59pt;text-indent: 0pt;line-height: 20pt;text-align: left;">Chen                                  <span class="s18">2</span></p><h2 style="padding-top: 2pt;padding-left: 65pt;text-indent: 0pt;text-align: left;">Residual Collection with Partial Rank Freezing</h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 27pt;text-align: left;">Hsin-Hsi                               24</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 59pt;text-indent: 0pt;line-height: 17pt;text-align: left;">Chen</p><p style="text-indent: 0pt;text-align: left;"><span><img width="838" height="712" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_031.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-top: 3pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">Automatic Local Analysis</p></li><li><p class="s3" style="padding-top: 39pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">user relevance feedback</p><ul id="l21"><li><h2 style="padding-top: 3pt;padding-left: 118pt;text-indent: -22pt;text-align: left;"><span class="p">Known relevant documents contain terms which can be used to describe a larger cluster of relevant documents </span>with assistance from the user (<span style=" color: #C30;">clustering</span>)</h2></li></ul></li><li><p class="s3" style="padding-top: 3pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">automatic analysis</p><ul id="l22"><li><p style="padding-top: 4pt;padding-left: 118pt;text-indent: -22pt;line-height: 94%;text-align: left;">Obtain a description (i.t.o terms) for a larger cluster of relevant documents <span class="h2">automatically</span></p></li><li><p style="padding-top: 5pt;padding-left: 118pt;text-indent: -22pt;line-height: 94%;text-align: left;">global strategy: global thesaurus-like structure is trained from <span class="h2">all documents </span><span class="s19">before querying</span></p></li><li><p style="padding-top: 5pt;padding-left: 118pt;text-indent: -22pt;line-height: 94%;text-align: left;">local strategy: terms from the <span class="h2">documents retrieved for a given query </span>are selected <span class="s19">at query time</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-top: 3pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">Local Feedback Strategy</p></li></ul></li><li><p class="s3" style="padding-top: 39pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">Internet</p><ul id="l23"><li><p style="padding-top: 3pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">client site</p><ul id="l24"><li><p class="s4" style="padding-top: 5pt;padding-left: 149pt;text-indent: -15pt;text-align: left;">Retrieving the text of 100 Web documents for local analysis would take too long</p></li></ul></li><li><p style="padding-top: 3pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">server site</p><ul id="l25"><li><p class="s4" style="padding-top: 4pt;padding-left: 149pt;text-indent: -15pt;text-align: left;">Analyzing the text of 100 Web documents would spend extra CPU time</p></li></ul></li></ul></li><li><p class="s3" style="padding-top: 2pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">Applications</p><ul id="l26"><li><p style="padding-top: 3pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Intranet</p></li><li><p style="padding-top: 4pt;padding-left: 118pt;text-indent: -22pt;line-height: 94%;text-align: left;">Specialized document collections, e.g., medical document collections</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li></ul></li><li><p class="s3" style="padding-left: 86pt;text-indent: -22pt;text-align: left;">stem</p><p class="s1" style="padding-top: 1pt;padding-left: 70pt;text-indent: -13pt;text-align: left;">Query Expansion- Local Clustering</p><ul id="l27"><li><p style="padding-top: 4pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">V(s): a non-empty subset of words which are grammatical variants of each other</p><p style="padding-left: 118pt;text-indent: 0pt;line-height: 26pt;text-align: left;">e.g., {polish, polishing, polished}</p></li><li><p style="padding-top: 1pt;padding-left: 118pt;text-indent: -22pt;line-height: 27pt;text-align: left;">A canonical form s of V(s) is called <span class="h2">a stem</span></p><p style="padding-left: 118pt;text-indent: 0pt;line-height: 27pt;text-align: left;">e.g., polish</p></li></ul></li><li><p class="s3" style="padding-top: 4pt;padding-left: 86pt;text-indent: -22pt;line-height: 36pt;text-align: left;">local document set D<span class="s8">l</span></p><ul id="l28"><li><p style="padding-left: 118pt;text-indent: -22pt;line-height: 26pt;text-align: left;">the set of documents retrieved for a given query</p></li></ul></li><li><p class="s3" style="padding-top: 3pt;padding-left: 86pt;text-indent: -22pt;line-height: 37pt;text-align: left;">local vocabulary V<span class="s8">l</span><span class="s10"> </span>(S<span class="s8">l</span>)</p><ul id="l29"><li><p style="padding-left: 118pt;text-indent: -22pt;line-height: 94%;text-align: left;">the set of all distinct words (stems) in the local document set</p><p class="s1" style="padding-top: 1pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">local cluster</p></li></ul></li><li><p class="s3" style="padding-top: 42pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">basic concept</p><ul id="l30"><li><p style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Expanding the query with terms correlated to the query terms</p></li><li><p style="padding-top: 3pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">The correlated terms are presented in the local clusters built from the local document set</p></li></ul></li><li><p class="s3" style="padding-top: 5pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">local clusters</p><ul id="l31"><li><p style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">association clusters: co-occurrences of pairs of terms in documents</p></li><li><p style="padding-top: 5pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">metric clusters: distance factor between two terms</p></li><li><p style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">scalar clusters: terms with similar neighborhoods have some synonymity relationship</p><p class="s1" style="padding-top: 1pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">Association Clusters</p></li></ul></li><li><p class="s7" style="padding-top: 42pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">idea</p><ul id="l32"><li><p class="s3" style="padding-top: 6pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Based on the co-occurrence of stems (or terms)</p><h1 style="padding-top: 1pt;text-indent: 0pt;text-align: right;">inside documents</h1></li></ul></li><li><p class="s7" style="padding-top: 9pt;padding-left: 88pt;text-indent: -88pt;text-align: right;">association matrix</p><p style="text-indent: 0pt;text-align: left;"><span><img width="49" height="1" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_032.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="6" height="4" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_033.png"/></span></p><ul id="l33"><li><p class="s3" style="padding-top: 12pt;padding-left: 118pt;text-indent: -22pt;line-height: 80%;text-align: left;">f<span class="s8">si,j</span>: the frequency of a stem s<span class="s8">i</span><span class="s10"> </span>in a document d<span class="s8">j </span>(<span class="s20">∈</span>D<span class="s8">l</span>)</p><p style="text-indent: 0pt;text-align: left;"><span><img width="144" height="75" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_034.png"/></span></p></li><li><p class="s3" style="padding-top: 4pt;padding-left: 118pt;text-indent: -22pt;line-height: 86%;text-align: left;">m=(f<span class="s8">si,j</span>): an association matrix with |S<span class="s8">l</span>| rows and |D<span class="s8">l</span>| columns</p></li><li><p class="s3" style="padding-top: 7pt;padding-left: 216pt;text-indent: -120pt;text-align: left;">: a local stem-stem association matrix</p><p style="text-indent: 0pt;text-align: left;"><span><img width="320" height="103" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_035.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="80" height="61" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_036.png"/></span></p><p class="s3" style="padding-top: 4pt;padding-left: 268pt;text-indent: -10pt;line-height: 127%;text-align: left;"><span class="p">: </span>a correlation between the stems s<span class="s8">u</span><span class="s10"> </span>and s an element in</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s3" style="padding-top: 3pt;padding-left: 23pt;text-indent: 0pt;text-align: left;">s<span class="s8">u,v</span>=c<span class="s8">u,v</span>: unnormalized matrix</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="336" height="111" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_037.png"/></span></p><p class="s3" style="padding-top: 25pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">: normalized matrix</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="137" height="177" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_038.png"/></span></p><p class="s3" style="padding-top: 24pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">local association cluster around the stem s<span class="s8">u</span></p><p style="padding-top: 15pt;padding-left: 125pt;text-indent: 0pt;text-align: left;">Take u-th row</p><p style="padding-top: 1pt;padding-left: 125pt;text-indent: 0pt;text-align: left;">Return the set of n largest values s<span class="s14">u,v</span><span class="s15"> </span>(u≠v)</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li></ul></li><li><p class="s7" style="padding-left: 86pt;text-indent: -22pt;text-align: left;">idea</p><p class="s1" style="padding-top: 2pt;padding-left: 64pt;text-indent: 0pt;text-align: left;">Metric Clusters</p><ul id="l34"><li><p class="s3" style="padding-top: 8pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Consider <span class="h1">the distance between two terms </span>in the computation of their correlation factor</p></li></ul></li><li><p class="s7" style="padding-top: 5pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">local stem-stem metric correlation matrix</p><ul id="l35"><li><p class="s3" style="padding-top: 10pt;padding-left: 118pt;text-indent: -22pt;line-height: 87%;text-align: left;">r(k<span class="s8">i</span>,k<span class="s8">j</span>): the number of words between keywords k<span class="s8">i</span><span class="s10"> </span>and k<span class="s8">j</span><span class="s10"> </span>in a same document</p></li><li><p class="s3" style="padding-top: 1pt;padding-bottom: 2pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">c<span class="s8">u,v</span>: metric correlation between stems s<span class="s8">u</span><span class="s10"> </span>and s<span class="s8">v</span></p><p style="padding-left: 119pt;text-indent: 0pt;text-align: left;"><span><img width="777" height="122" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_039.png"/></span></p><p class="s3" style="padding-top: 4pt;padding-left: 53pt;text-indent: 0pt;text-align: left;">s<span class="s8">u,v</span>=c<span class="s8">u,v</span>: unnormalized matrix</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="345" height="105" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_040.png"/></span></p><p class="s3" style="padding-top: 3pt;padding-left: 311pt;text-indent: 0pt;text-align: left;">: normalized matrix</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="9" height="121" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_041.png"/></span></p><p class="s16" style="padding-top: 1pt;padding-left: 41pt;text-indent: 0pt;text-align: left;"><span><img width="114" height="60" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_042.png"/></span>       <span class="s21">local</span><span class="s3"> metric cluster around the stem s</span><span class="s8">u</span></p><p style="padding-top: 10pt;padding-left: 149pt;text-indent: 0pt;text-align: left;">Take u-th row</p><p style="padding-top: 1pt;padding-left: 149pt;text-indent: 0pt;text-align: left;">Return the set of n largest values s<span class="s14">u,v</span><span class="s15"> </span>(u≠v)</p><p style="padding-left: 12pt;text-indent: 0pt;line-height: 24pt;text-align: left;">The row corresponding to a specific term</p><p style="padding-top: 1pt;padding-left: 12pt;text-indent: 0pt;text-align: left;">in a term co-occurrence matrix forms its neighborhood</p><p style="text-indent: 0pt;text-align: left;"/><p class="s1" style="padding-top: 1pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">Scalar Clusters</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li></ul></li><li><p class="s7" style="padding-left: 86pt;text-indent: -22pt;text-align: left;">idea</p><ul id="l36"><li><p class="s3" style="padding-top: 6pt;padding-left: 117pt;text-indent: -21pt;text-align: left;">Two stems with <span class="h1">similar neighborhoods </span>have</p><p class="s3" style="padding-top: 2pt;padding-left: 118pt;text-indent: 0pt;text-align: left;">synonymity relationship</p><p class="s4" style="padding-left: 18pt;text-indent: 0pt;line-height: 25pt;text-align: left;">The correlation value for s<span class="s22">u</span><span class="s23"> </span>and</p><p class="s4" style="padding-left: 18pt;text-indent: 0pt;line-height: 17pt;text-align: left;">s<span class="s22">v</span><span class="s23"> </span>in this matrix may be small</p><p style="text-indent: 0pt;text-align: left;"><span><img width="304" height="136" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_043.png"/></span></p></li><li><p class="s3" style="padding-left: 118pt;text-indent: -22pt;line-height: 31pt;text-align: left;">The relationship is <span class="h1">indirect </span>or <span class="h1">induced </span>by the</p><p class="s3" style="padding-left: 118pt;text-indent: 0pt;text-align: left;">neighborhood</p></li></ul></li><li><p class="s7" style="padding-top: 7pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">scalar association matrix</p><p style="text-indent: 0pt;text-align: left;"><span><img width="137" height="185" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_044.png"/></span></p><p class="s3" style="padding-top: 19pt;padding-left: 185pt;text-indent: 0pt;text-align: left;">local scalar cluster around the stem s<span class="s8">u</span></p><p style="padding-top: 15pt;padding-left: 191pt;text-indent: 0pt;text-align: left;">Take u-th row</p><p style="padding-top: 1pt;padding-left: 191pt;text-indent: 0pt;text-align: left;">Return the set of n largest values s<span class="s14">u,v</span><span class="s15"> </span>(u≠v)</p><p class="s17" style="padding-top: 1pt;padding-left: 104pt;text-indent: 0pt;text-align: left;">Interactive Search Formulation</p></li><li><p class="s7" style="padding-top: 19pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">neighbors of the query term s<span class="s12">v</span></p><p class="s24" style="text-indent: 0pt;line-height: 21pt;text-align: left;">u         v</p><p style="text-indent: 0pt;text-align: left;"/><ul id="l37"><li><p class="s3" style="padding-top: 4pt;padding-left: 118pt;text-indent: -22pt;line-height: 79%;text-align: left;">Terms s<span class="s8">u</span><span class="s10"> </span>belonging to clusters associated to s<span class="s8">v</span>, i.e., s <span class="s20">∈</span>S (n)</p></li><li><p class="s3" style="padding-top: 7pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">s<span class="s8">u</span><span class="s10"> </span>is called a searchonym of s<span class="s8">v</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;line-height: 27pt;text-align: left;">x</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 101pt;text-indent: 0pt;text-align: left;">x                      <span class="s25">x            </span>x                 <span class="s26">x</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="451" height="194" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_045.png"/></span></p><p style="text-indent: 0pt;line-height: 27pt;text-align: left;">Sv(n)</p><p style="padding-top: 20pt;padding-left: 16pt;text-indent: 0pt;text-align: left;">x</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;line-height: 27pt;text-align: left;">x</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;line-height: 27pt;text-align: left;">x</p><p style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Su</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;line-height: 27pt;text-align: left;">x</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;line-height: 22pt;text-align: right;">Sv</p><p style="text-indent: 0pt;line-height: 23pt;text-align: left;">x</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;line-height: 27pt;text-align: left;">x</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;line-height: 27pt;text-align: left;">x</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 151pt;text-indent: 0pt;line-height: 27pt;text-align: left;">x</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 20pt;padding-left: 38pt;text-indent: 0pt;text-align: center;">x                                                                        <span class="s27">x</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 151pt;text-indent: 0pt;text-align: left;">x</p><p style="padding-top: 9pt;padding-left: 59pt;text-indent: 0pt;line-height: 49pt;text-align: left;">Hsin-<span class="s28">x</span>Hsi       <span class="s29">x                          </span><span class="s30">x                   x</span></p><p style="padding-left: 59pt;text-indent: 0pt;line-height: 15pt;text-align: left;">Chen</p><p class="s17" style="padding-top: 6pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">Interactive Search Formulation</p><p class="s4" style="padding-top: 1pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">(<i>Continued</i>)</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li></ul></li><li><p class="s7" style="padding-top: 3pt;padding-left: 86pt;text-indent: -22pt;line-height: 37pt;text-align: left;">Algorithm</p><p class="s24" style="text-indent: 0pt;line-height: 21pt;text-align: left;">v</p><p style="text-indent: 0pt;text-align: left;"/><ul id="l38"><li><p class="s3" style="padding-top: 2pt;padding-left: 118pt;text-indent: -22pt;line-height: 90%;text-align: left;">For each stem s <span class="s20">∈</span>q, select m neighbor stems from the cluster S<span class="s8">v</span>(n) and add them to the query</p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="39" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_046.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="31" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_047.png"/></span></p></li><li><p class="s3" style="padding-left: 117pt;text-indent: -22pt;line-height: 30pt;text-align: left;">Merge normalized and unnormalized clusters</p></li></ul></li><li><p class="s31" style="padding-top: 4pt;padding-left: 86pt;text-indent: -22pt;line-height: 42pt;text-align: justify;">Extension<span class="s32">more</span><span class="s18"> rare </span><span class="p">large frequencies</span></p><ul id="l39"><li><p class="s3" style="padding-left: 118pt;text-indent: -22pt;line-height: 36pt;text-align: justify;">Let s<span class="s8">u</span><span class="s10"> </span>and s<span class="s8">v</span><span class="s10"> </span>be correlated with a c<span class="s8">u,v</span></p></li><li><p class="s3" style="padding-top: 2pt;padding-left: 118pt;text-indent: -22pt;line-height: 80%;text-align: justify;">If c<span class="s8">u,v</span><span class="s10"> </span>is larger than a predefined threshold, then a neighbor stem s<span class="s8">u’</span><span class="s10"> </span>of s<span class="s8">u</span><span class="s10"> </span>can also be interpreted as a neighbor stem of s<span class="s8">v</span>, and vice versa.</p><p class="s1" style="padding-top: 1pt;padding-left: 151pt;text-indent: -19pt;text-align: left;">Query Expansion through Local Context Analysis</p></li></ul></li><li><p class="s3" style="padding-top: 10pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">local analysis</p><ul id="l40"><li><p style="padding-top: 4pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Based on the set of documents <span class="h2">retrieved for the original query</span></p></li><li><p style="padding-top: 3pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Based on term co-occurrence <span class="h2">inside documents</span></p></li><li><p style="padding-top: 3pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Terms closest to <span class="h2">individual query terms </span>are selected</p></li></ul></li><li><p class="s3" style="padding-top: 2pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">global analysis</p><ul id="l41"><li><p style="padding-top: 3pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Based on the <span class="h2">whole document collection</span></p></li><li><p style="padding-top: 4pt;padding-left: 118pt;text-indent: -22pt;line-height: 94%;text-align: left;">Based on term co-occurrence <span class="h2">inside small contexts and phrase structures</span></p></li><li><p style="padding-top: 3pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Terms closest to <span class="h2">the whole query </span>are selected</p><p class="s4" style="padding-top: 1pt;padding-left: 97pt;text-indent: 34pt;text-align: left;"><span class="s1">Query Expansion through Local Context Analysis </span>(<i>Continued</i>)</p></li></ul></li><li><p class="s7" style="padding-top: 10pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">candidates</p><ul id="l42"><li><p class="s3" style="padding-top: 2pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">noun groups instead of simple keywords</p></li><li><p class="s3" style="padding-top: 5pt;padding-left: 118pt;text-indent: -22pt;line-height: 93%;text-align: left;">single noun, two adjacent nouns, or three adjacent nouns</p></li></ul></li><li><p class="s7" style="padding-top: 4pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">query expansion</p><ul id="l43"><li><p class="s3" style="padding-top: 5pt;padding-left: 118pt;text-indent: -22pt;line-height: 93%;text-align: left;">Concepts are selected from the top ranked documents (as in local analysis)</p></li><li><p class="s3" style="padding-top: 5pt;padding-left: 118pt;text-indent: -22pt;line-height: 93%;text-align: left;">Passages are used for determining co-occurrence (as in global analysis)</p><p class="s4" style="padding-top: 1pt;padding-left: 97pt;text-indent: 34pt;text-align: left;"><span class="s1">Query Expansion through Local Context Analysis </span>(<i>Continued</i>)</p></li></ul></li><li><p class="s3" style="padding-top: 10pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">algorithm</p><ul id="l44"><li><p style="padding-top: 4pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Retrieve the top <i>n </i>ranked <span class="s34">passages </span>using the original query</p></li><li><p style="padding-top: 4pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">For each concept in the top ranked passages, the similarity sim(q,c) between the whole query q and the concept c is computed using a variant of tf-idf ranking</p></li><li><p style="padding-top: 5pt;padding-left: 118pt;text-indent: -22pt;line-height: 94%;text-align: left;">The top m ranked concepts are added to the original query q</p><ul id="l45"><li><p class="s4" style="padding-top: 3pt;padding-left: 149pt;text-indent: -15pt;text-align: left;">Each concept is assigned a weight 1-0.9×i/m (i: rank)</p></li><li><p class="s4" style="padding-top: 3pt;padding-left: 149pt;text-indent: -15pt;text-align: left;">Each term in the original query is assigned a weight 2×original weight</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: right;">0.1</p><p style="padding-top: 4pt;padding-left: 321pt;text-indent: 0pt;text-align: left;">n: # of ranked passages</p><p style="text-indent: 0pt;text-align: left;"><span><img width="720" height="160" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_048.png"/></span></p><p class="s4" style="padding-top: 19pt;padding-left: 248pt;text-indent: 0pt;text-align: left;">for infrequent query term</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="456" height="138" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_049.png"/></span></p><p style="padding-left: 151pt;text-indent: 0pt;line-height: 91%;text-align: left;">correlation between c and k<span class="s14">i </span>pf<span class="s14">i,j</span><span class="s15"> </span>(pf<span class="s14">c,j</span>): freq of ki (c) in</p><p style="padding-left: 265pt;text-indent: 0pt;line-height: 25pt;text-align: left;">j-th passage</p><p style="padding-left: 157pt;text-indent: 0pt;line-height: 27pt;text-align: left;">association clusters (passage)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="505" height="129" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_050.png"/></span></p><p style="padding-top: 10pt;padding-left: 443pt;text-indent: -30pt;text-align: left;">N: # of passages in the collection</p><p style="text-indent: 0pt;text-align: left;"><span><img width="496" height="124" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_051.png"/></span></p><p style="padding-top: 1pt;padding-left: 455pt;text-indent: -42pt;line-height: 91%;text-align: left;">np<span class="s14">i</span>: # of passages containing term k<span class="s14">i</span></p><p style="padding-left: 413pt;text-indent: 0pt;line-height: 28pt;text-align: left;">np<span class="s14">c</span>: # of passages</p><p style="padding-left: 461pt;text-indent: 0pt;line-height: 26pt;text-align: left;">containing concept c</p><p style="padding-top: 14pt;padding-left: 59pt;text-indent: 0pt;line-height: 31pt;text-align: left;"><span class="s27">Hsin-Hsi </span>idf≥1<span class="s35">，當</span>np<span class="s35">很大</span>(<span class="s35">小</span>)<span class="s35">時，第二項可能小</span><span class="s27">39</span>(<span class="s35">大</span>)</p><p class="s35" style="padding-left: 59pt;text-indent: 0pt;line-height: 23pt;text-align: left;">於<span class="p">1</span></p><p class="s1" style="padding-top: 1pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">Automatic Global Analysis</p></li></ul></li></ul></li><li><p class="s3" style="padding-top: 39pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">local analysis</p><ul id="l46"><li><p style="padding-top: 4pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Extract information from the local set of documents (passages) retrieved</p></li></ul></li><li><p class="s3" style="padding-top: 3pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">global analysis</p><ul id="l47"><li><p style="padding-top: 5pt;padding-left: 118pt;text-indent: -22pt;line-height: 94%;text-align: left;">Expand the query using information from the whole set of documents in the collection</p></li><li><p style="padding-top: 2pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Issues</p><ul id="l48"><li><p class="s4" style="padding-top: 3pt;padding-left: 149pt;text-indent: -15pt;text-align: left;">How to build the thesaurus</p></li><li><p class="s4" style="padding-top: 2pt;padding-left: 149pt;text-indent: -15pt;text-align: left;">How to select the terms for query expansion</p></li></ul></li><li><p style="padding-top: 3pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Query expansion based on similarity thesaurus</p></li><li><p style="padding-top: 3pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Query expansion based on statistical thesaurus</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-top: 3pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">Similarity Thesaurus</p></li></ul></li><li><p class="s7" style="padding-top: 42pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">How to build the thesaurus</p><ul id="l49"><li><p class="s3" style="padding-top: 8pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Consider term to term relationship instead of co-occurrence</p></li></ul></li><li><p class="s7" style="padding-top: 5pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">How to select the terms for query expansion</p><ul id="l50"><li><p class="s3" style="padding-top: 7pt;padding-left: 118pt;text-indent: -22pt;text-align: left;">Consider the similarity to the whole query instead of individual query terms</p><p class="s1" style="padding-top: 1pt;padding-left: 71pt;text-indent: 0pt;text-align: center;">Concept Space</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li></ul></li></ul></li><li><p class="s3" style="padding-top: 3pt;padding-left: 80pt;text-indent: -22pt;text-align: left;">basic idea</p><ul id="l51"><li><p style="padding-top: 4pt;padding-left: 112pt;text-indent: -22pt;text-align: left;">Each term is indexed by the documents in which it appears</p></li><li><p style="padding-top: 4pt;padding-left: 112pt;text-indent: -22pt;line-height: 94%;text-align: left;">The role of terms and documents is interchanged in the concept space</p></li></ul></li><li><p class="s3" style="padding-top: 4pt;padding-left: 80pt;text-indent: -22pt;text-align: left;">t: the number of terms in the collection</p></li><li><p class="s3" style="padding-top: 2pt;padding-left: 80pt;text-indent: -22pt;text-align: left;">N: the number of documents in the collection</p></li><li><p class="s3" style="padding-top: 3pt;padding-left: 80pt;text-indent: -22pt;line-height: 37pt;text-align: left;">f<span class="s8">i,j</span>: the frequency of term k<span class="s8">i</span><span class="s10"> </span>in document d<span class="s8">j</span></p></li><li><p class="s3" style="padding-left: 80pt;text-indent: -22pt;line-height: 36pt;text-align: left;">t<span class="s8">j</span>: the number of distinct index terms in document d<span class="s8">j</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="200" height="120" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_052.png"/></span></p></li><li><p class="s3" style="padding-left: 80pt;text-indent: -22pt;line-height: 37pt;text-align: left;">itf<span class="s8">j</span>: inverse term frequency for document d<span class="s8">j</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="23" height="4" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_053.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="371" height="89" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_054.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="583" height="231" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_055.png"/></span></p><p class="s3" style="padding-top: 2pt;padding-left: 65pt;text-indent: -7pt;line-height: 300%;text-align: left;">Each term k<span class="s8">i</span><span class="s10"> </span>is associated with a vector k<span class="s8">i </span>where</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s3" style="padding-bottom: 4pt;padding-left: 65pt;text-indent: 0pt;line-height: 88%;text-align: left;">The relationship between two terms k<span class="s8">u</span><span class="s10"> </span>and k<span class="s8">v</span><span class="s10"> </span>is computed as</p><p style="padding-left: 155pt;text-indent: 0pt;text-align: left;"><span><img width="602" height="149" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_056.png"/></span></p><p class="s1" style="padding-top: 1pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">Query Expansion</p><p class="s17" style="padding-top: 2pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">using Global Similarity Thesaurus</p><p style="text-indent: 0pt;text-align: left;"><span><img width="264" height="114" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_057.png"/></span></p><ul id="l52"><li><p class="s7" style="padding-top: 29pt;padding-left: 86pt;text-indent: -22pt;text-align: left;">Represent the query in the concept space used for representation of the index terms</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s7" style="padding-left: 86pt;text-indent: -22pt;line-height: 86%;text-align: left;">Based on the global similarity thesaurus, compute a similarity sim(q,k<span class="s12">v</span>) between each term k<span class="s12">v</span><span class="s13"> </span>correlated to the query terms and the</p><p style="text-indent: 0pt;text-align: left;"><span><img width="576" height="136" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_058.png"/></span></p><p class="s7" style="padding-left: 86pt;text-indent: 0pt;line-height: 57%;text-align: left;">whole query q               <span class="s36">query term           </span><span class="s37">expand term</span></p><p class="s1" style="padding-top: 1pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">Query Expansion</p><p class="s17" style="padding-top: 2pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">using Global Similarity Thesaurus</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s7" style="padding-left: 86pt;text-indent: -22pt;text-align: left;">Expand the query with the top r ranked terms according to sim(q,k<span class="s12">v</span>)</p></li></ul></li></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 185pt;text-indent: 0pt;text-align: left;"><span><img width="372" height="130" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_059.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="569" height="441" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_060.png"/></span></p><p style="text-indent: 0pt;line-height: 26pt;text-align: left;">Expand term</p><p style="padding-left: 49pt;text-indent: 0pt;line-height: 27pt;text-align: center;">Kv</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;line-height: 27pt;text-align: left;">Kj</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;line-height: 27pt;text-align: left;">Ka</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;line-height: 27pt;text-align: left;">Qc</p><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;line-height: 27pt;text-align: left;">Kb</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 6pt;padding-left: 227pt;text-indent: 0pt;text-align: left;">Ki</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 119pt;text-indent: 0pt;text-align: left;">Q={Ka,Kb}</p><p class="s1" style="padding-top: 1pt;padding-left: 82pt;text-indent: 0pt;text-align: center;">GVSM vs. Query Expansion</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 47pt;text-indent: 0pt;text-align: left;"><span><img width="833" height="277" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_061.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 49pt;text-indent: 0pt;text-align: left;"><span><img width="755" height="135" alt="image" src="Unit%202%20-%20Chapter%205_files/Image_062.png"/></span></p><p style="padding-top: 6pt;padding-left: 64pt;text-indent: 0pt;text-align: left;">Only the top r ranked terms are used for query expansion.</p></body></html>
